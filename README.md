# **AI Infra工程师48周数学学习计划：工程实战版**

**版本**：v3.0（终极可执行版）  
**原则**：每周产出物可量化、工作闭环、失败熔断  
**强度**：每周10-12小时（工作日1.5小时 + 周末3-4小时）

---

## **Q1：数值线性代数（1-12周）—— 量化压缩的数学基建**

### **月度目标分解**
- **1月（1-4周）**：范数 + SVD → 能识别可压缩层
- **2月（5-8周）**：QR + 特征值 → 能诊断数值病态
- **3月（9-12周）**：浮点数 + 综合 → 产出量化分析工具V1

---

### **Week 1：矩阵范数——点燃第一把火**

**📅 日任务分解**  
- **周一 06:30-07:30**：读《Numerical Linear Algebra》Lecture 1-2，理解范数是"长度"的推广  
- **周二 12:30-13:00**：手写`def vector_norm(x, p=2)`，计算3个随机向量的L1/L2/∞范数  
- **周三 21:00-21:45**：读Lecture 3，理解算子范数 `||A|| = max_{||x||=1} ||Ax||`  
- **周四 06:30-07:30**：手写`def matrix_norm_fro(A)`和`def matrix_norm_op(A)`，对比`numpy.linalg.norm`  
- **周五 12:30-13:00**：**工作应用**：在你的推理服务中dump一个`nn.Linear`层，计算其算子范数  
- **周六 09:00-11:00**：整理本周代码，写README（3句话：这是什么、怎么用、测了什么）  
- **周日 19:00-20:00**：**周检验**：默写5个范数定义 + 运行代码无error

**✅ 本周产出物**：GitHub仓库`math-for-infra` + `norms.py` + 1份工作简报（PDF，含1个层的范数数据）

 **🔍 效果检验**  ：代码能正确计算随机矩阵的L2算子范数，误差<1e-6

---

### **Week 2：SVD几何直觉——可视化震撼**

**📅 日任务分解**  
- **周一 06:30-07:30**：读Lecture 4-5，看3Blue1Brown《SVD的精髓》视频1遍  
- **周二 12:30-13:00**：用Matplotlib画一个2x2矩阵的SVD变换动画（圆→椭圆）  
- **周三 21:00-21:45**：读Lecture 18，理解SVD存在性定理，**跳过证明，只看结论**  
- **周四 06:30-07:30**：用`torch.svd`分解一个随机矩阵，打印U, Σ, V的形状  
- **周五 12:30-13:00**：**工作应用**：dump你模型最大的`W_q`矩阵（如4096x4096），观察Σ的奇异值分布  
- **周六 09:00-11:30**：用对数坐标绘制奇异值衰减曲线，计算前10个奇异值的能量占比  
- **周日 19:00-20:00**：**周检验**：能向家人解释SVD的几何意义（旋转-拉伸-旋转）

**✅ 本周产出物**：SVD动画GIF + 奇异值衰减图 + 技术笔记（300字，配3张图）

 **🔍 效果检验**  ：解释为什么σ₁ > σ₂ > ... 且都≥0

---

### **Week 3：SVD压缩实战——第一次工作闭环**

**📅 日任务分解**  
- **周一 06:30-07:30**：读Eckart-Young定理（Lecture 19），**只记结论**：`||A-A_k||₂ = σ_{k+1}`  
- **周二 12:30-13:00**：手写`def low_rank_approx(A, energy=0.95)`，自动选择保留的秩k  
- **周三 21:00-21:45**：在BERT-base的`W_q`上测试：保留95%能量，秩从4096降到多少？  
- **周四 06:30-07:30**：实现压缩后推理：`compressed_layer = U[:,:k] @ (Σ[:k,:k] @ V[:k,:])`  
- **周五 12:30-13:00**：**工作应用**：测量压缩层的推理延迟（用`torch.cuda.Event`计时）  
- **周六 09:00-12:00**：扫描3个不同层的压缩比-速度-精度曲线，找出Pareto最优  
- **周日 19:00-20:30**：**周检验**：写1页报告《层X适合压缩到秩128，速度提升30%，精度下降0.5%》

**✅ 本周产出物**：`svd_compression.py` + 压缩性能报告 + 1份代码CR（Code Review）自检

 **🔍 效果检验**  ：压缩后模型的困惑度（PPL）上升<1.0

---

### **Week 4：QR分解——数值稳定的盾牌**

**📅 日任务分解**  
- **周一 06:30-07:30**：读Lecture 7-8，理解Gram-Schmidt过程，**手算2个向量**的正交化  
- **周二 12:30-13:00**：手写`def gram_schmidt(A)`，测试`||Q^TQ - I||`的数值误差  
- **周三 21:00-21:45**：读Lecture 10，理解Householder反射的几何意义（镜像变换）  
- **周四 06:30-07:30**：手写`def householder_qr(A)`，对比误差（应该比Gram-Schmidt小10倍）  
- **周五 12:30-13:00**：**工作应用**：分析一个LayerNorm层的Gram矩阵`G = X^TX`，用QR判断其正交性  
- **周六 09:00-11:30**：实现稳定版最小二乘求解器 `def lstsq_qr(A, b)`  
- **周日 19:00-20:30**：**周检验**：解释为什么Householder在FP16下更稳定

**✅ 本周产出物**：`stable_qr.py` + 误差对比图 + 1份"数值稳定性"笔记

 **🔍 效果检验**  ：对于条件数`κ=10⁶`的矩阵，QR求解误差<1e-4，而Gram-Schmidt误差>0.1

---

### **Q1月度回顾模板（Week 4周日晚上执行）**

**📊 数据看板**  
- **本月投入**：理论12小时 + 实践16小时 = 28小时
- **代码行数**：约500行
- **工作影响**：已识别3个可压缩层，1个高风险量化层

**✅ 完成清单**  
- [ ] 4个Py文件（norms, svd, qr, compression）
- [ ] 2份性能报告
- [ ] 1次组内分享（若未完成，列入下月）
- [ ] GitHub仓库 stars ≥ 1（自己也算）

**❓ 问题复盘**  
- **本周卡住**：Householder反射的符号选择没懂 → 已标记，Q2 revisit
- **工作太忙**：Week 3有2天没学习 → 次周周末补回4小时

**🎯 下月目标**  
- **核心**：掌握特征值与条件数，产出《量化风险评级系统》
- **改进**：增加每日学习日志（1句话），减少周末集中时间

---

### **Week 5-8：特征值与谱分析（模式同Week 1-4，略细节）**

**Week 5-6核心任务**：  
- **理论**：幂法/反幂法求主/次特征值  
- **实践**：分析Attention矩阵`QK^T`的谱分布，判断是否low-rank  
- **产出**：`spectral_analyzer.py` + Attention谱特性报告  
- **检验**：前10个特征值占总能量的90%

**Week 7-8核心任务**：  
- **理论**：特征值条件数`κ(λ)`  
- **实践**：识别量化后特征值漂移的敏感层  
- **产出**：`eigenvalue_utils.py` + 敏感层黑名单  
- **检验**：能预测哪层量化后特征值变化>10%

---

### **Week 9-10：浮点数与误差模型**

**Week 9任务**：  
- **理论**：IEEE 754标准，Machine epsilon  
- **实践**：模拟FP16累加误差，`sum([1e-4]*10000)`  
- **产出**：`fp_simulator.py`  
- **检验**：能算出FP16的`ε_mach = 9.77e-4`

**Week 10任务**：  
- **理论**：Catastrophic cancellation  
- **实践**：分析LayerNorm的`mean`计算在FP16下的精度损失  
- **产出**：《FP16推理数值稳定性白皮书》1页  
- **检验**：解释为什么LayerNorm累加用FP32

---

### **Week 11-12：Q1综合大项目**

**Week 11任务**：  
- **需求**：设计**量化敏感性分析平台**（命令行工具）  
- **架构**：输入模型 → 输出逐层风险评级（A/B/C级）  
- **编码**：集成前10周所有函数

**Week 12任务**：  
- **测试**：在OPT-1.3B上验证，对比人工经验  
- **分享**：组内15分钟演示（3分钟背景 + 5分钟演示 + 5分钟数据 + 2分钟Q&A）  
- **文档**：写博客《如何用数学避免量化翻车》

---

## **Q2：数值稳定性与优化（13-24周）**

### **月度目标**
- **4月（13-16周）**：数值稳定算子库  
- **5月（17-20周）**：优化算法与量化搜索  
- **6月（21-24周）**：性能建模 + Q2综合

---

### **Week 13-14：Log-sum-exp与Softmax稳定性**

**Week 13任务**：  
- 手写`def stable_softmax(x)`，用`x - max(x)`技巧  
- 对比`torch.softmax`，误差<1e-7  
- **工作应用**：分析FlashAttention的分块softmax

**Week 14任务**：  
- 实现`def logsumexp(x)`，理解为什么`log(∑exp(x))`会溢出  
- 在GPT-2的logits上测试，temperature=2.0时的数值范围  
- **产出**：`stable_ops.py`模块初版

 **🔍 检验**  ：在`x = [1000.0, 1001.0, 1002.0]`上，稳定版不溢出

---

### **Week 15-16：并行计算与Roofline模型**

**Week 15任务**：  
- 理解Roofline Model：`Performance = min(π, β)`  
- 测量A100的峰值算力（312 TFLOPS）和带宽（2 TB/s）  
- **产出**：`roofline_analyzer.py`

**Week 16任务**：  
- 分析一个自定义CUDA kernel的**计算密度**（FLOP/Byte）  
- 判断是**Compute-bound**还是**Memory-bound**  
- **工作应用**：优化一个Memory-bound的算子

---

### **Week 17-18：优化算法基础（SGD/Adam）**

**Week 17任务**：  
- 手写`class SGD`和`class Adam`，实现`step()`方法  
- 在QAT场景下对比Adam vs SGD的收敛曲线  
- **产出**：`optimizers.py`

**Week 18任务**：  
- 理解Newton法二阶收敛，手写`def newton_search(f, grad, hess, x0)`  
- 用Newton法搜索最佳量化scale（对比网格搜索快10倍）  
- **工作应用**：集成到GPTQ/AWQ的scale搜索

---

### **Week 19-20：综合项目——数值稳定算子库**

**Week 19任务**：  
- 封装`stable_ops.py`：LayerNorm, Softmax, GELU, SwiGLU  
- 每个算子必须通过**数值精度测试**（误差<1e-5）  
- **检验**：在FP16下，与FP32 baseline的相对误差<0.1%

**Week 20任务**：  
- 写单元测试（pytest）+ 性能测试（`torch.cuda.Event`）  
- 文档：每个函数都写**数学原理** + **使用陷阱**  
- **产出**：GitHub Release v0.1

---

### **Q2季度回顾（Week 24周日执行）**

**📊 数据看板**  
- **本月投入**：理论15小时 + 实践20小时 = 35小时  
- **代码行数**：+800行  
- **工作影响**：解决了2个FP16溢出bug，QAT训练提速15%

**✅ 完成清单**  
- [ ] `stable_ops.py`通过10个单元测试  
- [ ] `roofline_analyzer.py`准确预测3个kernel的瓶颈  
- [ ] 组内分享《Newton法在量化搜索中的应用》

**❓ 问题复盘**  
- **牛顿法Hessian计算太慢**：已用对角近似加速  
- **并行计算理论太抽象**：通过Nsight Compute工具反向理解

**🎯 Q3目标**  
- **核心**：用数学模型预测推理延迟，误差<10%  
- **改进**：每双周1次组内micro-share（5分钟）

---

## **Q3：性能建模与概率收尾（25-36周）**

### **月度目标**
- **7月（25-28周）**：性能预测模型  
- **8月（29-32周）**：采样与分布  
- **9月（33-36周）**：排队论 + 综合

---

### **Week 25-28：推理延迟的数学建模**

**Week 25-26任务**：  
- 收集100条性能数据（模型size, batch, seq_len, GPU, 延迟）  
- 用多重线性回归：`latency = α·M + β·C + γ·B + δ`（M=memory, C=compute, B=batch）  
- **产出**：`latency_predictor.py`，R² > 0.85

**Week 27-28任务**：  
- 在10个新配置上验证预测误差<15%  
- 工具化：集成到CI，自动预测新模型的延迟  
- **工作应用**：指导客户选择最优batch size

**🔍 检验**：预测A100上OPT-30B的延迟，误差<10ms

---

### **Week 29-32：概率论收尾（采样 + 排队论）**

**Week 29-30任务（采样）**：  
- 理解Top-p/k采样的截断分布数学  
- 实现`def top_p_sampling(logits, p=0.9)`  
- **产出**：`sampling_analysis.py`

**Week 31-32任务（排队论）**：  
- M/M/1模型：`L = λ/(μ-λ)`  
- 建模你的推理服务：请求到达率λ，服务率μ，计算平均延迟  
- **工作应用**：容量规划，避免服务过载

---

### **Q3季度回顾（Week 36周日执行）**

**📊 数据看板**  
- **数据**：预测模型服务10次，客户采纳率80%  
- **代码**：+600行  
- **工作**：容量规划避免1次线上事故

**✅ 完成清单**  
- [ ] 延迟预测模型误差<15%  
- [ ] 采样延迟分析优化10%  
- [ ] 技术博客《M/M/1模型在推理服务的应用》

**🎯 Q4目标**  
- **核心**：开源1个工具 + 发表1篇技术博客  
- **改进**：开始写周记（1句话总结），便于年度复盘

---

## **Q4：开源与影响力（37-48周）**

### **月度目标**
- **10月（37-40周）**：工具开源  
- **11月（41-44周）**：技术博客体系  
- **12月（45-48周）**：年度复盘 + 规划

---

### **Week 37-40：量化风险分析工具开源**

**Week 37-38任务**：  
- 重构Q1的量化分析工具：CLI接口、配置文件、日志系统  
- 写README： gif演示 + 安装指南 + 3个例子  
- **产出**：GitHub开源`quant-risk-analyzer`

**Week 39-40任务**：  
- 在Hugging Face社区推广：发帖子 + 回复issue  
- 目标：2周内获得20+ stars  
- **检验**：star数截图

---

### **Week 41-44：技术博客矩阵**

**Week 41任务**：  
- 选1个数学概念，写**深度**博客（2000字 + 5个图 + 代码）  
- 选题：《SVD在大模型压缩中的工程实践》

**Week 42任务**：  
- 把Q1-Q4的笔记整理成**系列博客**（5篇短博客，每篇500字）  
- 发布到知乎/掘金/个人博客

**Week 43任务**：  
- 写1篇**综述**：《AI Infra工程师的计算数学学习路径》  
- 包含：路线图、资源、避坑指南

**Week 44任务**：  
- 联系1个技术媒体（如机器之心）投稿  
- 或在内部分享会上做45分钟主题演讲

---

### **Week 45-48：年度收官与规划**

**Week 45-46任务**：  
- 整理全年GitHub：README更新 + Release v1.0  
- 写年度总结：投入时间、代码量、工作影响、学习曲线

**Week 47任务**：  
- **组内大分享**：1小时《数学驱动的推理优化2024》  
- 内容：工具演示 + 数据报告 + 下年计划

**Week 48任务**：  
- **个人复盘**：用KPT模板（Keep/Problem/Try）  
- **下年规划**：如果继续学，方向是什么？（PDE数值解？编译器优化？）

---

## **周度检验清单（每周日执行）**

**快速版（5分钟）**：  
- [ ] 本周代码提交GitHub了吗？  
- [ ] 工作应用有数据记录吗？  
- [ ] 1个新概念能用自己的话讲吗？  
- [ ] 下周任务明确吗？

**详细版（15分钟）**：  
- **投入时间**：理论__小时，实践__小时，工作应用__小时  
- **产出物**：代码__行，文档__字，报告__份  
- **卡点**：__（若无填"无"）  
- **求助**：__（需要谁的帮助？）

---

## **季度回顾仪式（每12周周日，2小时）**

**Step 1：数据化成果（30分钟）**  
- 打开GitHub Insights，截图代码提交日历  
- 打开工作日志，统计有多少次"数学帮助我解决了X问题"  
- 打开博客后台，记录阅读量和互动数

**Step 2：问题复盘（30分钟）**  
- **为什么这周进度慢？**（工作/家庭/方法/动力）  
- **哪个数学工具迟迟用不上？**（说明优先级错配，砍掉）  
- **哪个知识点反复卡？**（标记为"硬骨头"，Q2 revisit）

**Step 3：调整计划（30分钟）**  
- **加速**：哪部分内容可以压缩？（如并行计算理论跳过）  
- **减速**：哪部分需要加练？（如数值稳定性反复出错）  
- **暂停**：哪部分暂时无用？（如排队论若工作不涉及）

**Step 4：庆祝与激励（30分钟）**  
- 列出3个"本月最骄傲的瞬间"（如"成功预测了某层量化崩溃"）  
- 奖励自己一个小礼物（如一本数学科普书）  
- 发一条朋友圈/微博，记录里程碑

---

## **熔断与重启机制（防放弃）**

**如果你连续3周未完成计划**：  
1. **立即熔断**：停止学习3天，彻底放松  
2. **诊断原因**：  
   - 工作太忙？→ 将计划强度降为50%（每周5小时）  
   - 内容太难？→ 回退2周，从简单内容重新开始  
   - 动力不足？→ 找学习伙伴，或加入开源社区  
3. **重启仪式**：从最简单的任务开始（如手写范数函数），快速获得正反馈

**如果某周实在无法投入10小时**：  
- **保底任务**：只看1小时理论（开倍速），不写代码  
- **心理安慰**：告诉自己"维持习惯就是胜利"

---

## **年度成功画像（48周后）**

**技术能力**：  
- 能独立分析任意大模型的数值特性  
- 工具箱里有5个可复用的数学模块  
- 能写技术博客，能组内分享，能定位线上数值问题

**职业影响**：  
- 成为团队"量化/压缩"技术专家  
- 简历新增"精通AI模型数值分析与优化"  
- 有GitHub开源项目 + 技术博客矩阵

**个人成长**：  
- 数学从"恐惧"变为"工具"  
- 建立"理论→实践→反馈"的终身学习系统  
- 养成每天1小时深度工作的习惯

---

## **最后一句话**

**这个计划不是枷锁，而是GPS**。你可以超速，可以绕路，可以临时停车。只要你每周日打开它，看一眼"我现在在哪，要去哪"，它就算完成了使命。

**真正的学习不是填完48周的格子，而是48周后，数学成为你思维的默认选项之一。**

